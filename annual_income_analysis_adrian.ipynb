{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "import math \n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE, KMeansSMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss, TomekLinks, ClusterCentroids, AllKNN\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from imblearn.metrics import specificity_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dane z https://www.kaggle.com/datasets/amirhosseinmirzaie/americancitizenincome/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./income.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>223881</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>149118</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>109209</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>229566</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>?</td>\n",
       "      <td>148657</td>\n",
       "      <td>Preschool</td>\n",
       "      <td>1</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt     education  education.num  \\\n",
       "0   40  Self-emp-not-inc  223881   Prof-school             15   \n",
       "1   30           Private  149118       HS-grad              9   \n",
       "2   46           Private  109209  Some-college             10   \n",
       "3   32           Private  229566     Assoc-voc             11   \n",
       "4   54                 ?  148657     Preschool              1   \n",
       "\n",
       "       marital.status      occupation   relationship   race     sex  \\\n",
       "0  Married-civ-spouse  Prof-specialty        Husband  White    Male   \n",
       "1            Divorced    Craft-repair  Not-in-family  White  Female   \n",
       "2  Married-civ-spouse    Adm-clerical        Husband  White    Male   \n",
       "3  Married-civ-spouse   Other-service        Husband  White    Male   \n",
       "4  Married-civ-spouse               ?           Wife  White  Female   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0         99999             0              70  United-States   >50K  \n",
       "1             0             0              40  United-States  <=50K  \n",
       "2             0             0              40  United-States   >50K  \n",
       "3             0             0              60  United-States   >50K  \n",
       "4             0             0              40         Mexico  <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             25000 non-null  int64 \n",
      " 1   workclass       25000 non-null  object\n",
      " 2   fnlwgt          25000 non-null  int64 \n",
      " 3   education       25000 non-null  object\n",
      " 4   education.num   25000 non-null  int64 \n",
      " 5   marital.status  25000 non-null  object\n",
      " 6   occupation      25000 non-null  object\n",
      " 7   relationship    25000 non-null  object\n",
      " 8   race            25000 non-null  object\n",
      " 9   sex             25000 non-null  object\n",
      " 10  capital.gain    25000 non-null  int64 \n",
      " 11  capital.loss    25000 non-null  int64 \n",
      " 12  hours.per.week  25000 non-null  int64 \n",
      " 13  native.country  25000 non-null  object\n",
      " 14  income          25000 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.00000</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.60916</td>\n",
       "      <td>1.896611e+05</td>\n",
       "      <td>10.076320</td>\n",
       "      <td>1083.144040</td>\n",
       "      <td>87.489800</td>\n",
       "      <td>40.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.68660</td>\n",
       "      <td>1.054713e+05</td>\n",
       "      <td>2.576967</td>\n",
       "      <td>7321.971568</td>\n",
       "      <td>402.830246</td>\n",
       "      <td>12.309706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.00000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.00000</td>\n",
       "      <td>1.179830e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.00000</td>\n",
       "      <td>1.782110e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.00000</td>\n",
       "      <td>2.370682e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.00000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age        fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "count  25000.00000  2.500000e+04   25000.000000  25000.000000  25000.000000   \n",
       "mean      38.60916  1.896611e+05      10.076320   1083.144040     87.489800   \n",
       "std       13.68660  1.054713e+05       2.576967   7321.971568    402.830246   \n",
       "min       17.00000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.00000  1.179830e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.00000  1.782110e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.00000  2.370682e+05      12.000000      0.000000      0.000000   \n",
       "max       90.00000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours.per.week  \n",
       "count    25000.000000  \n",
       "mean        40.442800  \n",
       "std         12.309706  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>53</td>\n",
       "      <td>?</td>\n",
       "      <td>158352</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>8614</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>27</td>\n",
       "      <td>?</td>\n",
       "      <td>174163</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>48</td>\n",
       "      <td>?</td>\n",
       "      <td>193047</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>67</td>\n",
       "      <td>?</td>\n",
       "      <td>157403</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>6418</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>65</td>\n",
       "      <td>?</td>\n",
       "      <td>191380</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>9386</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24507</th>\n",
       "      <td>68</td>\n",
       "      <td>?</td>\n",
       "      <td>108683</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24605</th>\n",
       "      <td>48</td>\n",
       "      <td>?</td>\n",
       "      <td>184513</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24741</th>\n",
       "      <td>49</td>\n",
       "      <td>?</td>\n",
       "      <td>228372</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24864</th>\n",
       "      <td>76</td>\n",
       "      <td>?</td>\n",
       "      <td>28221</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Canada</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24940</th>\n",
       "      <td>62</td>\n",
       "      <td>?</td>\n",
       "      <td>68461</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt     education  education.num      marital.status  \\\n",
       "185     53         ?  158352       Masters             14       Never-married   \n",
       "583     27         ?  174163  Some-college             10  Married-civ-spouse   \n",
       "619     48         ?  193047       HS-grad              9  Married-civ-spouse   \n",
       "1189    67         ?  157403   Prof-school             15  Married-civ-spouse   \n",
       "1543    65         ?  191380          10th              6  Married-civ-spouse   \n",
       "...    ...       ...     ...           ...            ...                 ...   \n",
       "24507   68         ?  108683  Some-college             10  Married-civ-spouse   \n",
       "24605   48         ?  184513     Bachelors             13  Married-civ-spouse   \n",
       "24741   49         ?  228372  Some-college             10  Married-civ-spouse   \n",
       "24864   76         ?   28221       HS-grad              9  Married-civ-spouse   \n",
       "24940   62         ?   68461     Doctorate             16  Married-civ-spouse   \n",
       "\n",
       "      occupation   relationship                race     sex  capital.gain  \\\n",
       "185            ?  Not-in-family               White  Female          8614   \n",
       "583            ?           Wife               White  Female             0   \n",
       "619            ?        Husband               White    Male             0   \n",
       "1189           ?        Husband               White    Male          6418   \n",
       "1543           ?        Husband               White    Male          9386   \n",
       "...          ...            ...                 ...     ...           ...   \n",
       "24507          ?           Wife               White  Female             0   \n",
       "24605          ?        Husband               White    Male             0   \n",
       "24741          ?        Husband               White    Male             0   \n",
       "24864          ?        Husband               White    Male             0   \n",
       "24940          ?        Husband  Amer-Indian-Eskimo    Male             0   \n",
       "\n",
       "       capital.loss  hours.per.week native.country income  \n",
       "185               0              35  United-States   >50K  \n",
       "583               0              40  United-States   >50K  \n",
       "619               0              40  United-States   >50K  \n",
       "1189              0              10  United-States   >50K  \n",
       "1543              0              50  United-States   >50K  \n",
       "...             ...             ...            ...    ...  \n",
       "24507             0              12  United-States   >50K  \n",
       "24605             0              80  United-States   >50K  \n",
       "24741             0              20  United-States   >50K  \n",
       "24864             0              40         Canada   >50K  \n",
       "24940             0              40  United-States   >50K  \n",
       "\n",
       "[149 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['occupation'] == '?') & (df['income'] != '<=50K')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1429\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education.num        0\n",
       "marital.status       0\n",
       "occupation        1434\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital.gain         0\n",
       "capital.loss         0\n",
       "hours.per.week       0\n",
       "native.country     437\n",
       "income               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education.num     0\n",
       "marital.status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital.gain      0\n",
       "capital.loss      0\n",
       "hours.per.week    0\n",
       "native.country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>223881</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>149118</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>109209</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>229566</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>Private</td>\n",
       "      <td>111963</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt     education  education.num  \\\n",
       "0   40  Self-emp-not-inc  223881   Prof-school             15   \n",
       "1   30           Private  149118       HS-grad              9   \n",
       "2   46           Private  109209  Some-college             10   \n",
       "3   32           Private  229566     Assoc-voc             11   \n",
       "5   63           Private  111963  Some-college             10   \n",
       "\n",
       "       marital.status      occupation   relationship   race     sex  \\\n",
       "0  Married-civ-spouse  Prof-specialty        Husband  White    Male   \n",
       "1            Divorced    Craft-repair  Not-in-family  White  Female   \n",
       "2  Married-civ-spouse    Adm-clerical        Husband  White    Male   \n",
       "3  Married-civ-spouse   Other-service        Husband  White    Male   \n",
       "5  Married-civ-spouse  Prof-specialty        Husband  White    Male   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0         99999             0              70  United-States   >50K  \n",
       "1             0             0              40  United-States  <=50K  \n",
       "2             0             0              40  United-States   >50K  \n",
       "3             0             0              60  United-States   >50K  \n",
       "5             0             0              16  United-States  <=50K  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **age**: Wiek osoby.\n",
    "- **workclass**: Ogólny termin wskazujący status zatrudnienia osoby.\n",
    "- **fnlwgt**: Waga końcowa, reprezentująca liczbę osób, którą ta dana reprezentuje (próbka reprezentatywna).\n",
    "- **education**: Najwyższy poziom wykształcenia osiągnięty przez osobę.\n",
    "- **education.num**: Najwyższy poziom wykształcenia osiągnięty przez osobę w formie numerycznej.\n",
    "- **marital.status**: Status cywilny osoby. Zwróć uwagę, że \"Married-civ-spouse\" oznacza cywilnego małżonka, a \"Married-AF-spouse\" odnosi się do małżonka w Siłach Zbrojnych.\n",
    "- **occupation**: Ogólny typ zawodu osoby.\n",
    "- **relationship**: Relacja tej osoby z innymi, na przykład małżonek (mąż). Każdy punkt danych ma tylko jedną relację.\n",
    "- **race**: Rasa.\n",
    "- **sex**: Płeć biologiczna osoby.\n",
    "- **capital.gain**: Zyski kapitałowe osoby.\n",
    "- **capital.loss**: Straty kapitałowe osoby.\n",
    "- **hours.per.week**: Liczba godzin, które osoba zadeklarowała jako przepracowane w tygodniu.\n",
    "- **native.country**: Kraj pochodzenia.\n",
    "- **income**: Dochód, mniejszy lub równy $50,000 (`<=50K`) lub większy (`>50K`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_value_counts(data):\n",
    "    categorical_cols = data.select_dtypes(include=['object']).columns \n",
    "    value_counts = {col: data[col].value_counts() for col in categorical_cols}\n",
    "    return value_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>46</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>142210</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>22</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>302347</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>4416</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>72</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>121004</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>19</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>344858</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>62</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>159908</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9404</th>\n",
       "      <td>68</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>174695</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11464</th>\n",
       "      <td>67</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>137192</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>21</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>232719</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18429</th>\n",
       "      <td>19</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>43887</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21111</th>\n",
       "      <td>52</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>198262</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21194</th>\n",
       "      <td>65</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>27012</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24398</th>\n",
       "      <td>65</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>172949</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2414</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age    workclass  fnlwgt     education  education.num  \\\n",
       "1071    46  Without-pay  142210       HS-grad              9   \n",
       "1674    22  Without-pay  302347       HS-grad              9   \n",
       "2333    72  Without-pay  121004       HS-grad              9   \n",
       "2632    19  Without-pay  344858       HS-grad              9   \n",
       "8033    62  Without-pay  159908  Some-college             10   \n",
       "9404    68  Without-pay  174695  Some-college             10   \n",
       "11464   67  Without-pay  137192       HS-grad              9   \n",
       "14631   21  Without-pay  232719       HS-grad              9   \n",
       "18429   19  Without-pay   43887       HS-grad              9   \n",
       "21111   52  Without-pay  198262       HS-grad              9   \n",
       "21194   65  Without-pay   27012       7th-8th              4   \n",
       "24398   65  Without-pay  172949       HS-grad              9   \n",
       "\n",
       "              marital.status         occupation relationship  \\\n",
       "1071      Married-civ-spouse  Machine-op-inspct         Wife   \n",
       "1674           Never-married  Handlers-cleaners    Own-child   \n",
       "2333      Married-civ-spouse      Other-service      Husband   \n",
       "2632           Never-married    Farming-fishing    Own-child   \n",
       "8033      Married-civ-spouse       Adm-clerical         Wife   \n",
       "9404   Married-spouse-absent    Farming-fishing    Unmarried   \n",
       "11464     Married-civ-spouse       Adm-clerical      Husband   \n",
       "14631          Never-married       Craft-repair    Own-child   \n",
       "18429          Never-married    Farming-fishing    Own-child   \n",
       "21111     Married-civ-spouse       Adm-clerical         Wife   \n",
       "21194                Widowed    Farming-fishing    Unmarried   \n",
       "24398     Married-civ-spouse   Transport-moving      Husband   \n",
       "\n",
       "                     race     sex  capital.gain  capital.loss  hours.per.week  \\\n",
       "1071                White  Female             0             0              25   \n",
       "1674                White    Male          4416             0              40   \n",
       "2333                White    Male             0             0              55   \n",
       "2632                White    Male             0             0              20   \n",
       "8033                White  Female             0             0              16   \n",
       "9404                White  Female             0             0              25   \n",
       "11464  Asian-Pac-Islander    Male             0             0              12   \n",
       "14631               Black    Male             0             0              40   \n",
       "18429               White    Male             0             0              10   \n",
       "21111               White  Female             0             0              30   \n",
       "21194               White  Female             0             0              50   \n",
       "24398               White    Male          2414             0              20   \n",
       "\n",
       "      native.country income  \n",
       "1071   United-States  <=50K  \n",
       "1674   United-States  <=50K  \n",
       "2333   United-States  <=50K  \n",
       "2632   United-States  <=50K  \n",
       "8033   United-States  <=50K  \n",
       "9404   United-States  <=50K  \n",
       "11464    Philippines  <=50K  \n",
       "14631  United-States  <=50K  \n",
       "18429  United-States  <=50K  \n",
       "21111  United-States  <=50K  \n",
       "21194  United-States  <=50K  \n",
       "24398  United-States  <=50K  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"workclass\"] == \"Without-pay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: workclass\n",
      "workclass\n",
      "Private             17157\n",
      "Self-emp-not-inc     1908\n",
      "Local-gov            1535\n",
      "State-gov             992\n",
      "Self-emp-inc          820\n",
      "Federal-gov           725\n",
      "Without-pay            12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: education\n",
      "education\n",
      "HS-grad         7520\n",
      "Some-college    5144\n",
      "Bachelors       3873\n",
      "Masters         1231\n",
      "Assoc-voc       1008\n",
      "11th             805\n",
      "Assoc-acdm       760\n",
      "10th             647\n",
      "Prof-school      420\n",
      "7th-8th          410\n",
      "9th              351\n",
      "Doctorate        301\n",
      "12th             298\n",
      "5th-6th          228\n",
      "1st-4th          121\n",
      "Preschool         32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: marital.status\n",
      "marital.status\n",
      "Married-civ-spouse       10830\n",
      "Never-married             7451\n",
      "Divorced                  3214\n",
      "Separated                  718\n",
      "Widowed                    642\n",
      "Married-spouse-absent      277\n",
      "Married-AF-spouse           17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: occupation\n",
      "occupation\n",
      "Prof-specialty       3119\n",
      "Craft-repair         3083\n",
      "Exec-managerial      3064\n",
      "Adm-clerical         2843\n",
      "Sales                2764\n",
      "Other-service        2460\n",
      "Machine-op-inspct    1507\n",
      "Transport-moving     1183\n",
      "Handlers-cleaners    1062\n",
      "Farming-fishing       767\n",
      "Tech-support          700\n",
      "Protective-serv       487\n",
      "Priv-house-serv       104\n",
      "Armed-Forces            6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: relationship\n",
      "relationship\n",
      "Husband           9599\n",
      "Not-in-family     5885\n",
      "Own-child         3422\n",
      "Unmarried         2484\n",
      "Wife              1081\n",
      "Other-relative     678\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: race\n",
      "race\n",
      "White                 19879\n",
      "Black                  2179\n",
      "Asian-Pac-Islander      684\n",
      "Amer-Indian-Eskimo      232\n",
      "Other                   175\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: sex\n",
      "sex\n",
      "Male      15640\n",
      "Female     7509\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: native.country\n",
      "native.country\n",
      "United-States                 21129\n",
      "Mexico                          474\n",
      "Philippines                     133\n",
      "Germany                          96\n",
      "Puerto-Rico                      81\n",
      "India                            79\n",
      "Cuba                             77\n",
      "Canada                           76\n",
      "El-Salvador                      71\n",
      "Jamaica                          66\n",
      "England                          64\n",
      "Vietnam                          55\n",
      "Dominican-Republic               54\n",
      "South                            54\n",
      "China                            52\n",
      "Guatemala                        48\n",
      "Italy                            47\n",
      "Japan                            45\n",
      "Columbia                         44\n",
      "Poland                           43\n",
      "Haiti                            33\n",
      "Taiwan                           30\n",
      "Portugal                         26\n",
      "Nicaragua                        24\n",
      "Ecuador                          24\n",
      "Peru                             23\n",
      "Iran                             22\n",
      "France                           21\n",
      "Greece                           18\n",
      "Trinadad&Tobago                  16\n",
      "Cambodia                         14\n",
      "Ireland                          14\n",
      "Thailand                         14\n",
      "Hong                             14\n",
      "Laos                             13\n",
      "Outlying-US(Guam-USVI-etc)       12\n",
      "Yugoslavia                       12\n",
      "Hungary                          11\n",
      "Honduras                         10\n",
      "Scotland                         10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: income\n",
      "income\n",
      "<=50K    17359\n",
      ">50K      5790\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = categorical_value_counts(df)\n",
    "\n",
    "for col, counts in value_counts.items():\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do obliczania V-Cramera\n",
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    min_dim = min(confusion_matrix.shape) - 1\n",
    "    return np.sqrt(chi2 / (n * min_dim))\n",
    "\n",
    "def cramers_v_output(v_cramer, variable1, variable2):\n",
    "    print(f\"V-Cramer dla zmiennych {variable1} & {variable2}: {v_cramer}\")\n",
    "\n",
    "    # Interpretacja wyniku\n",
    "    if v_cramer < 0.1:\n",
    "        print(\"Bardzo słaba zależność\")\n",
    "    elif v_cramer < 0.3:\n",
    "        print(\"Słaba zależność\")\n",
    "    elif v_cramer < 0.5:\n",
    "        print(\"Umiarkowana zależność\")\n",
    "    else:\n",
    "        print(\"Silna zależność\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V-Cramer dla zmiennych relationship & marital.status: 0.4883047419738085\n",
      "Umiarkowana zależność\n"
     ]
    }
   ],
   "source": [
    "\n",
    "contingency_table = pd.crosstab(df['relationship'], df['marital.status'])\n",
    "\n",
    "v_cramer = cramers_v(contingency_table)\n",
    "cramers_v_output(v_cramer, 'relationship', 'marital.status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V-Cramer dla zmiennych workclass & occupation: 0.21386591543583022\n",
      "Słaba zależność\n"
     ]
    }
   ],
   "source": [
    "contingency_table = pd.crosstab(df['workclass'], df['occupation'])\n",
    "\n",
    "v_cramer = cramers_v(contingency_table)\n",
    "cramers_v_output(v_cramer, 'workclass', 'occupation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V-Cramer dla zmiennych race & native.country: 0.42552233243500237\n",
      "Umiarkowana zależność\n"
     ]
    }
   ],
   "source": [
    "contingency_table = pd.crosstab(df['race'], df['native.country'])\n",
    "\n",
    "\n",
    "v_cramer = cramers_v(contingency_table)\n",
    "cramers_v_output(v_cramer, 'race', 'native.country')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>223881</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>149118</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>109209</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>229566</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>Private</td>\n",
       "      <td>111963</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt     education  education.num  \\\n",
       "0   40  Self-emp-not-inc  223881   Prof-school             15   \n",
       "1   30           Private  149118       HS-grad              9   \n",
       "2   46           Private  109209  Some-college             10   \n",
       "3   32           Private  229566     Assoc-voc             11   \n",
       "5   63           Private  111963  Some-college             10   \n",
       "\n",
       "       marital.status      occupation   relationship   race     sex  \\\n",
       "0  Married-civ-spouse  Prof-specialty        Husband  White    Male   \n",
       "1            Divorced    Craft-repair  Not-in-family  White  Female   \n",
       "2  Married-civ-spouse    Adm-clerical        Husband  White    Male   \n",
       "3  Married-civ-spouse   Other-service        Husband  White    Male   \n",
       "5  Married-civ-spouse  Prof-specialty        Husband  White    Male   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week native.country  income_>50K  \n",
       "0         99999             0              70  United-States            1  \n",
       "1             0             0              40  United-States            0  \n",
       "2             0             0              40  United-States            1  \n",
       "3             0             0              60  United-States            1  \n",
       "5             0             0              16  United-States            0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df,columns=['income'], drop_first=True, dtype=int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "      <th>native.region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>223881</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>149118</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>109209</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>229566</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>Private</td>\n",
       "      <td>111963</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt     education  education.num  \\\n",
       "0   40  Self-emp-not-inc  223881   Prof-school             15   \n",
       "1   30           Private  149118       HS-grad              9   \n",
       "2   46           Private  109209  Some-college             10   \n",
       "3   32           Private  229566     Assoc-voc             11   \n",
       "5   63           Private  111963  Some-college             10   \n",
       "\n",
       "       marital.status      occupation   relationship   race     sex  \\\n",
       "0  Married-civ-spouse  Prof-specialty        Husband  White    Male   \n",
       "1            Divorced    Craft-repair  Not-in-family  White  Female   \n",
       "2  Married-civ-spouse    Adm-clerical        Husband  White    Male   \n",
       "3  Married-civ-spouse   Other-service        Husband  White    Male   \n",
       "5  Married-civ-spouse  Prof-specialty        Husband  White    Male   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week  income_>50K  native.region  \n",
       "0         99999             0              70            1  North America  \n",
       "1             0             0              40            0  North America  \n",
       "2             0             0              40            1  North America  \n",
       "3             0             0              60            1  North America  \n",
       "5             0             0              16            0  North America  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_mapping = {\n",
    "    'Cambodia': 'Asia',\n",
    "    'Canada': 'North America',\n",
    "    'China': 'Asia',\n",
    "    'Columbia': 'South America',\n",
    "    'Cuba': 'Caribbean',\n",
    "    'Dominican-Republic': 'Caribbean',\n",
    "    'Ecuador': 'South America',\n",
    "    'El-Salvador': 'Central America',\n",
    "    'England': 'Europe',\n",
    "    'France': 'Europe',\n",
    "    'Germany': 'Europe',\n",
    "    'Greece': 'Europe',\n",
    "    'Guatemala': 'Central America',\n",
    "    'Haiti': 'Caribbean',\n",
    "    'Honduras': 'Central America',\n",
    "    'Hong': 'Asia',\n",
    "    'Hungary': 'Europe',\n",
    "    'India': 'Asia',\n",
    "    'Iran': 'Middle East',\n",
    "    'Ireland': 'Europe',\n",
    "    'Italy': 'Europe',\n",
    "    'Jamaica': 'Caribbean',\n",
    "    'Japan': 'Asia',\n",
    "    'Laos': 'Asia',\n",
    "    'Mexico': 'North America',\n",
    "    'Nicaragua': 'Central America',\n",
    "    'Outlying-US(Guam-USVI-etc)': 'US Territories',\n",
    "    'Peru': 'South America',\n",
    "    'Philippines': 'Asia',\n",
    "    'Poland': 'Europe',\n",
    "    'Portugal': 'Europe',\n",
    "    'Puerto-Rico': 'Caribbean',\n",
    "    'Scotland': 'Europe',\n",
    "    'South': 'Asia',\n",
    "    'Taiwan': 'Asia',\n",
    "    'Thailand': 'Asia',\n",
    "    'Trinadad&Tobago': 'Caribbean',\n",
    "    'United-States': 'North America',\n",
    "    'Vietnam': 'Asia',\n",
    "    'Yugoslavia': 'Europe'\n",
    "}\n",
    "\n",
    "# Dodanie kolumny native.region na podstawie mapowania\n",
    "df['native.region'] = df['native.country'].replace(region_mapping)\n",
    "\n",
    "df = df.drop(columns=['native.country'])\n",
    "# Sprawdzenie wyników\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['occupation'].value_counts().plot(kind='bar', color='orange', edgecolor='black', figsize=(8, 6))\n",
    "plt.title('Rozkład zmiennej kategorycznej', fontsize=14)\n",
    "plt.xlabel('Kategorie', fontsize=12)\n",
    "plt.ylabel('Częstotliwość', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['workclass'].value_counts().plot(kind='bar', color='orange', edgecolor='black', figsize=(8, 6))\n",
    "plt.title('Rozkład zmiennej kategorycznej', fontsize=14)\n",
    "plt.xlabel('Kategorie', fontsize=12)\n",
    "plt.ylabel('Częstotliwość', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do obliczenia WoE i IV\n",
    "def calculate_woe_iv(data, feature, target):\n",
    "    \"\"\"\n",
    "    Oblicza WoE i IV dla zmiennej kategorycznej.\n",
    "    \"\"\"\n",
    "    df = data[[feature, target]].copy()\n",
    "    total_good = df[target].sum() \n",
    "    total_bad = len(df) - total_good  \n",
    "    \n",
    "    grouped = df.groupby(feature)[target].agg(['count', 'sum'])\n",
    "    grouped['bad'] = grouped['count'] - grouped['sum']\n",
    "    grouped['good_dist'] = grouped['sum'] / total_good\n",
    "    grouped['bad_dist'] = grouped['bad'] / total_bad\n",
    "\n",
    "    grouped['woe'] = np.log((grouped['good_dist'] + 1e-6) / (grouped['bad_dist'] + 1e-6))\n",
    "    grouped['iv'] = (grouped['good_dist'] - grouped['bad_dist']) * grouped['woe']\n",
    "\n",
    "    total_iv = grouped['iv'].sum()\n",
    "    grouped = grouped.reset_index()\n",
    "    return grouped, total_iv\n",
    "\n",
    "\n",
    "# Funkcja do wizualizacji WoE\n",
    "def plot_woe(woe_iv_df, feature):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(woe_iv_df[feature], woe_iv_df['iv'], color='skyblue', edgecolor='black')\n",
    "    plt.axhline(0, color='red', linestyle='--', linewidth=1)  # Pozioma linia zerowa\n",
    "    plt.title(f'Weight of Evidence (WoE) dla {feature}', fontsize=14)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.ylabel('WoE', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     relationship  count   sum   bad  good_dist  bad_dist       woe        iv\n",
      "0         Husband   9599  4370  5229   0.754750  0.301227  0.918520  0.416569\n",
      "1   Not-in-family   5885   643  5242   0.111054  0.301976 -1.000329  0.190985\n",
      "2  Other-relative    678    29   649   0.005009  0.037387 -2.009985  0.065080\n",
      "3       Own-child   3422    46  3376   0.007945  0.194481 -3.197706  0.596489\n",
      "4       Unmarried   2484   168  2316   0.029016  0.133418 -1.525627  0.159279\n",
      "5            Wife   1081   534   547   0.092228  0.031511  1.073905  0.065204\n",
      "\n",
      "Total IV for 'relationship': 1.4936\n"
     ]
    }
   ],
   "source": [
    "# Obliczenie WoE i IV dla kolumny 'education'\n",
    "woe_iv_df, total_iv = calculate_woe_iv(df, 'relationship', 'income_>50K')\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(woe_iv_df)\n",
    "print(f\"\\nTotal IV for 'relationship': {total_iv:.4f}\")\n",
    "\n",
    "# Wizualizacja WoE\n",
    "# plot_woe(woe_iv_df, 'workclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          marital.status  count   sum   bad  good_dist  bad_dist       woe  \\\n",
      "0               Divorced   3214   360  2854   0.062176  0.164410 -0.972384   \n",
      "1      Married-AF-spouse     17     9     8   0.001554  0.000461  1.214237   \n",
      "2     Married-civ-spouse  10830  4921  5909   0.849914  0.340400  0.915012   \n",
      "3  Married-spouse-absent    277    27   250   0.004663  0.014402 -1.127500   \n",
      "4          Never-married   7451   362  7089   0.062522  0.408376 -1.876663   \n",
      "5              Separated    718    54   664   0.009326  0.038251 -1.411238   \n",
      "6                Widowed    642    57   585   0.009845  0.033700 -1.230510   \n",
      "\n",
      "         iv  \n",
      "0  0.099411  \n",
      "1  0.001328  \n",
      "2  0.466211  \n",
      "3  0.010980  \n",
      "4  0.649052  \n",
      "5  0.040820  \n",
      "6  0.029354  \n",
      "\n",
      "Total IV for 'marital.status': 1.2972\n"
     ]
    }
   ],
   "source": [
    "# Obliczenie WoE i IV dla kolumny 'education'\n",
    "woe_iv_df, total_iv = calculate_woe_iv(df, 'marital.status', 'income_>50K')\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(woe_iv_df)\n",
    "print(f\"\\nTotal IV for 'marital.status': {total_iv:.4f}\")\n",
    "\n",
    "# Wizualizacja WoE\n",
    "# plot_woe(woe_iv_df, 'workclass')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 race  count   sum    bad  good_dist  bad_dist       woe  \\\n",
      "0  Amer-Indian-Eskimo    232    27    205   0.004663  0.011809 -0.929065   \n",
      "1  Asian-Pac-Islander    684   188    496   0.032470  0.028573  0.127841   \n",
      "2               Black   2179   300   1879   0.051813  0.108244 -0.736724   \n",
      "3               Other    175    17    158   0.002936  0.009102 -1.131172   \n",
      "4               White  19879  5258  14621   0.908117  0.842272  0.075271   \n",
      "\n",
      "         iv  \n",
      "0  0.006639  \n",
      "1  0.000498  \n",
      "2  0.041573  \n",
      "3  0.006975  \n",
      "4  0.004956  \n",
      "\n",
      "Total IV for 'race': 0.0606\n"
     ]
    }
   ],
   "source": [
    "woe_iv_df, total_iv = calculate_woe_iv(df, 'race', 'income_>50K')\n",
    "\n",
    "print(woe_iv_df)\n",
    "print(f\"\\nTotal IV for 'race': {total_iv:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     native.region  count   sum    bad  good_dist  bad_dist       woe  \\\n",
      "0             Asia    503   152    351   0.026252  0.020220  0.261062   \n",
      "1        Caribbean    327    46    281   0.007945  0.016188 -0.711670   \n",
      "2  Central America    153    11    142   0.001900  0.008180 -1.459549   \n",
      "3           Europe    362   114    248   0.019689  0.014287  0.320729   \n",
      "4      Middle East     22    12     10   0.002073  0.000576  1.279048   \n",
      "5    North America  21679  5448  16231   0.940933  0.935019  0.006304   \n",
      "6    South America     91     7     84   0.001209  0.004839 -1.386308   \n",
      "7   US Territories     12     0     12   0.000000  0.000691 -6.539996   \n",
      "\n",
      "         iv  \n",
      "0  0.001575  \n",
      "1  0.005866  \n",
      "2  0.009167  \n",
      "3  0.001733  \n",
      "4  0.001914  \n",
      "5  0.000037  \n",
      "6  0.005032  \n",
      "7  0.004521  \n",
      "\n",
      "Total IV for 'native.region': 0.0298\n"
     ]
    }
   ],
   "source": [
    "woe_iv_df, total_iv = calculate_woe_iv(df, 'native.region', 'income_>50K')\n",
    "\n",
    "print(woe_iv_df)\n",
    "print(f\"\\nTotal IV for 'native.region': {total_iv:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_woe(woe_iv_df, feature):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(woe_iv_df[feature], woe_iv_df['woe'], color='skyblue', edgecolor='black')\n",
    "    plt.axhline(0, color='red', linestyle='--', linewidth=1)  # Pozioma linia zerowa\n",
    "    plt.title(f'Weight of Evidence (WoE) dla {feature}', fontsize=14)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.ylabel('WoE', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "df['income_>50K'].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "\n",
    "plt.title('Rozkład zmiennej Income', fontsize=14)\n",
    "plt.xlabel('Income', fontsize=12)\n",
    "plt.ylabel('Liczba wystąpień', fontsize=12)\n",
    "plt.xticks(rotation=0)  # Ustawienie etykiet osi X poziomo\n",
    "\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasa pozytywna to: 25.01% zbioru danych.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Klasa pozytywna to: {df['income_>50K'].value_counts()[1] / (df['income_>50K'].value_counts()[0] + df['income_>50K'].value_counts()[1]) * 100:0.2f}% zbioru danych.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    23149.000000\n",
      "mean      1005.553458\n",
      "std       7347.306965\n",
      "min      -4356.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max      99999.000000\n",
      "Name: net.capital, dtype: float64\n",
      "   capital.gain  capital.loss  net.capital\n",
      "0         99999             0        99999\n",
      "1             0             0            0\n",
      "2             0             0            0\n",
      "3             0             0            0\n",
      "5             0             0            0\n"
     ]
    }
   ],
   "source": [
    "# Utworzenie nowej zmiennej jako różnicy między capital.gain i capital.loss\n",
    "df['net.capital'] = df['capital.gain'] - df['capital.loss']\n",
    "\n",
    "# Sprawdzenie statystyk nowej zmiennej\n",
    "print(df['net.capital'].describe())\n",
    "\n",
    "# Podgląd wartości\n",
    "print(df[['capital.gain', 'capital.loss', 'net.capital']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n"
     ]
    }
   ],
   "source": [
    "print((df['net.capital'] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df['net.capital'], color='skyblue')\n",
    "\n",
    "plt.title(\"Histogram zmiennej Net Capital\", fontsize=14)\n",
    "plt.xlabel(\"Net Capital\", fontsize=12)\n",
    "plt.ylabel(\"Liczba wysątpień\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "      <th>native.region</th>\n",
       "      <th>net.capital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>223881</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "      <td>99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>149118</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>North America</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>109209</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>229566</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>Private</td>\n",
       "      <td>111963</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>North America</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt     education  education.num  \\\n",
       "0   40  Self-emp-not-inc  223881   Prof-school             15   \n",
       "1   30           Private  149118       HS-grad              9   \n",
       "2   46           Private  109209  Some-college             10   \n",
       "3   32           Private  229566     Assoc-voc             11   \n",
       "5   63           Private  111963  Some-college             10   \n",
       "\n",
       "       marital.status      occupation   relationship   race     sex  \\\n",
       "0  Married-civ-spouse  Prof-specialty        Husband  White    Male   \n",
       "1            Divorced    Craft-repair  Not-in-family  White  Female   \n",
       "2  Married-civ-spouse    Adm-clerical        Husband  White    Male   \n",
       "3  Married-civ-spouse   Other-service        Husband  White    Male   \n",
       "5  Married-civ-spouse  Prof-specialty        Husband  White    Male   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week  income_>50K  native.region  \\\n",
       "0         99999             0              70            1  North America   \n",
       "1             0             0              40            0  North America   \n",
       "2             0             0              40            1  North America   \n",
       "3             0             0              60            1  North America   \n",
       "5             0             0              16            0  North America   \n",
       "\n",
       "   net.capital  \n",
       "0        99999  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "5            0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['education', 'marital.status', 'capital.loss', 'capital.gain', 'native.region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23149, 11)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, cmap, title):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    conf_matrix_with_labels = pd.DataFrame(conf_matrix, columns=labels, index=labels)\n",
    "    sns.heatmap(conf_matrix_with_labels, annot=True, fmt='d', cmap=cmap)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test, labels=('neg', 'pos'), cmap='Blues'):\n",
    "    \"\"\"\n",
    "    Funkcja do obliczania i wyświetlania metryk modelu, wizualizacji macierzy konfuzji\n",
    "    oraz wyświetlania raportu klasyfikacji.\n",
    "\n",
    "    Parametry:\n",
    "    - model: sklearn-like model\n",
    "        Wytrenowany model predykcyjny.\n",
    "    - X_train, Y_train: array-like\n",
    "        Dane treningowe i ich etykiety.\n",
    "    - X_test, Y_test: array-like\n",
    "        Dane testowe i ich etykiety.\n",
    "    - labels: tuple, optional\n",
    "        Etykiety dla osi macierzy konfuzji (domyślnie ('neg', 'pos')).\n",
    "    - cmap: str, optional\n",
    "        Kolorystyka mapy cieplnej (domyślnie 'Blues').\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # Metryki dla danych treningowych\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "    print('Metryki dla danych treningowych:')\n",
    "    print(f'Accuracy: {acc_train:.4f}')\n",
    "    print(f'AUC: {auc_train:.4f}')\n",
    "    print(f'F1: {f1_train:.4f}')\n",
    "    print('\\nClassification Report dla danych treningowych:')\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "    # Wizualizacja macierzy konfuzji dla danych treningowych\n",
    "    plot_confusion_matrix(y_train, y_pred_train, labels, cmap, 'Confusion Matrix (Train)')\n",
    "\n",
    "    # Metryki dla danych testowych\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    print('\\nMetryki dla danych testowych:')\n",
    "    print(f'Accuracy: {acc_test:.4f}')\n",
    "    print(f'AUC: {auc_test:.4f}')\n",
    "    print(f'F1: {f1_test:.4f}')\n",
    "    print('\\nClassification Report dla danych testowych:')\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "    # Wizualizacja macierzy konfuzji dla danych testowych\n",
    "    plot_confusion_matrix(y_test, y_pred_test, labels, cmap, 'Confusion Matrix (Test)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23149 entries, 0 to 24999\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             23149 non-null  int64 \n",
      " 1   workclass       23149 non-null  object\n",
      " 2   fnlwgt          23149 non-null  int64 \n",
      " 3   education.num   23149 non-null  int64 \n",
      " 4   occupation      23149 non-null  object\n",
      " 5   relationship    23149 non-null  object\n",
      " 6   race            23149 non-null  object\n",
      " 7   sex             23149 non-null  object\n",
      " 8   hours.per.week  23149 non-null  int64 \n",
      " 9   income_>50K     23149 non-null  int64 \n",
      " 10  net.capital     23149 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23149, 11)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "      <th>net.capital</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_Not-in-family</th>\n",
       "      <th>relationship_Other-relative</th>\n",
       "      <th>relationship_Own-child</th>\n",
       "      <th>relationship_Unmarried</th>\n",
       "      <th>relationship_Wife</th>\n",
       "      <th>race_Asian-Pac-Islander</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "      <th>sex_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>223881</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>149118</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>109209</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>229566</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>111963</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education.num  hours.per.week  income_>50K  net.capital  \\\n",
       "0   40  223881             15              70            1        99999   \n",
       "1   30  149118              9              40            0            0   \n",
       "2   46  109209             10              40            1            0   \n",
       "3   32  229566             11              60            1            0   \n",
       "5   63  111963             10              16            0            0   \n",
       "\n",
       "   workclass_Local-gov  workclass_Private  workclass_Self-emp-inc  \\\n",
       "0                    0                  0                       0   \n",
       "1                    0                  1                       0   \n",
       "2                    0                  1                       0   \n",
       "3                    0                  1                       0   \n",
       "5                    0                  1                       0   \n",
       "\n",
       "   workclass_Self-emp-not-inc  ...  relationship_Not-in-family  \\\n",
       "0                           1  ...                           0   \n",
       "1                           0  ...                           1   \n",
       "2                           0  ...                           0   \n",
       "3                           0  ...                           0   \n",
       "5                           0  ...                           0   \n",
       "\n",
       "   relationship_Other-relative  relationship_Own-child  \\\n",
       "0                            0                       0   \n",
       "1                            0                       0   \n",
       "2                            0                       0   \n",
       "3                            0                       0   \n",
       "5                            0                       0   \n",
       "\n",
       "   relationship_Unmarried  relationship_Wife  race_Asian-Pac-Islander  \\\n",
       "0                       0                  0                        0   \n",
       "1                       0                  0                        0   \n",
       "2                       0                  0                        0   \n",
       "3                       0                  0                        0   \n",
       "5                       0                  0                        0   \n",
       "\n",
       "   race_Black  race_Other  race_White  sex_Male  \n",
       "0           0           0           1         1  \n",
       "1           0           0           1         0  \n",
       "2           0           0           1         1  \n",
       "3           0           0           1         1  \n",
       "5           0           0           1         1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['workclass', 'occupation', 'relationship', 'race', 'sex']\n",
    "df = pd.get_dummies(df,columns=columns, drop_first=True, dtype=int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Od tego momentu mamy final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23149, 35)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['income_>50K'])\n",
    "y = df['income_>50K']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/pvrf3bcn1_19pfvwcv0z6n_m0000gn/T/ipykernel_68716/854401252.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_oversampling = pd.concat([results_oversampling, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE()</td>\n",
       "      <td>0.845644</td>\n",
       "      <td>0.700621</td>\n",
       "      <td>0.656577</td>\n",
       "      <td>0.907786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADASYN()</td>\n",
       "      <td>0.842765</td>\n",
       "      <td>0.691789</td>\n",
       "      <td>0.657159</td>\n",
       "      <td>0.903769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BorderlineSMOTE()</td>\n",
       "      <td>0.840317</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.647846</td>\n",
       "      <td>0.903578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVMSMOTE()</td>\n",
       "      <td>0.845932</td>\n",
       "      <td>0.699507</td>\n",
       "      <td>0.661234</td>\n",
       "      <td>0.906639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomOverSampler()</td>\n",
       "      <td>0.848956</td>\n",
       "      <td>0.695958</td>\n",
       "      <td>0.691502</td>\n",
       "      <td>0.900708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Method  Accuracy  Precision    Recall  Specificity\n",
       "0              SMOTE()  0.845644   0.700621  0.656577     0.907786\n",
       "1             ADASYN()  0.842765   0.691789  0.657159     0.903769\n",
       "2    BorderlineSMOTE()  0.840317   0.688312  0.647846     0.903578\n",
       "3           SVMSMOTE()  0.845932   0.699507  0.661234     0.906639\n",
       "4  RandomOverSampler()  0.848956   0.695958  0.691502     0.900708"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "methods = [SMOTE(), ADASYN(), BorderlineSMOTE(), SVMSMOTE(), RandomOverSampler()]\n",
    "results_oversampling = pd.DataFrame(columns=['Method', 'Accuracy', 'Precision', 'Recall', 'Specificity'])\n",
    "\n",
    "for method in methods:\n",
    "    X_resampled, y_resampled = method.fit_resample(X_train, y_train)\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Dodanie nowego wiersza jako DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "        'Method': [str(method)],\n",
    "        'Accuracy': [accuracy_score(y_test, y_test_pred)],\n",
    "        'Precision': [precision_score(y_test, y_test_pred, zero_division=0)],\n",
    "        'Recall': [recall_score(y_test, y_test_pred, zero_division=0)],\n",
    "        'Specificity': [specificity_score(y_test, y_test_pred)]\n",
    "    })\n",
    "    \n",
    "    # Połączenie wyników\n",
    "    results_oversampling = pd.concat([results_oversampling, new_row], ignore_index=True)\n",
    "\n",
    "results_oversampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/pvrf3bcn1_19pfvwcv0z6n_m0000gn/T/ipykernel_68716/3056045029.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_undersampling = pd.concat([results_undersampling, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomUnderSampler()</td>\n",
       "      <td>0.819294</td>\n",
       "      <td>0.597803</td>\n",
       "      <td>0.823632</td>\n",
       "      <td>0.817869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NearMiss()</td>\n",
       "      <td>0.756659</td>\n",
       "      <td>0.504982</td>\n",
       "      <td>0.825960</td>\n",
       "      <td>0.733882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TomekLinks()</td>\n",
       "      <td>0.852844</td>\n",
       "      <td>0.724516</td>\n",
       "      <td>0.653667</td>\n",
       "      <td>0.918309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ClusterCentroids()</td>\n",
       "      <td>0.703384</td>\n",
       "      <td>0.451939</td>\n",
       "      <td>0.935972</td>\n",
       "      <td>0.626937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AllKNN()</td>\n",
       "      <td>0.818431</td>\n",
       "      <td>0.598027</td>\n",
       "      <td>0.811409</td>\n",
       "      <td>0.820738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Method  Accuracy  Precision    Recall  Specificity\n",
       "0  RandomUnderSampler()  0.819294   0.597803  0.823632     0.817869\n",
       "1            NearMiss()  0.756659   0.504982  0.825960     0.733882\n",
       "2          TomekLinks()  0.852844   0.724516  0.653667     0.918309\n",
       "3    ClusterCentroids()  0.703384   0.451939  0.935972     0.626937\n",
       "4              AllKNN()  0.818431   0.598027  0.811409     0.820738"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = [RandomUnderSampler(), NearMiss(), TomekLinks(), ClusterCentroids(), AllKNN()]\n",
    "results_undersampling = pd.DataFrame(columns=['Method', 'Accuracy', 'Precision', 'Recall', 'Specificity'])\n",
    "\n",
    "for method in methods:\n",
    "    X_resampled, y_resampled = method.fit_resample(X_train, y_train)\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    new_row = pd.DataFrame({\n",
    "        'Method': [str(method)],\n",
    "        'Accuracy': [accuracy_score(y_test, y_test_pred)],\n",
    "        'Precision': [precision_score(y_test, y_test_pred, zero_division=0)],\n",
    "        'Recall': [recall_score(y_test, y_test_pred, zero_division=0)],\n",
    "        'Specificity': [specificity_score(y_test, y_test_pred)]\n",
    "    })\n",
    "    \n",
    "    # Połączenie wyników\n",
    "    results_undersampling = pd.concat([results_undersampling, new_row], ignore_index=True)\n",
    "\n",
    "results_undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metryki dla danych treningowych:\n",
      "Accuracy: 0.9999\n",
      "AUC: 0.9999\n",
      "F1: 0.9999\n",
      "\n",
      "Classification Report dla danych treningowych:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10735\n",
      "           1       1.00      1.00      1.00     10735\n",
      "\n",
      "    accuracy                           1.00     21470\n",
      "   macro avg       1.00      1.00      1.00     21470\n",
      "weighted avg       1.00      1.00      1.00     21470\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metryki dla danych testowych:\n",
      "Accuracy: 0.8407\n",
      "AUC: 0.7869\n",
      "F1: 0.6789\n",
      "\n",
      "Classification Report dla danych testowych:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      5227\n",
      "           1       0.68      0.68      0.68      1718\n",
      "\n",
      "    accuracy                           0.84      6945\n",
      "   macro avg       0.79      0.79      0.79      6945\n",
      "weighted avg       0.84      0.84      0.84      6945\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use tomek links\n",
    "tl = TomekLinks()\n",
    "X_resampled, y_resampled = tl.fit_resample(X_train, y_train)\n",
    "#use smote on tomek links\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_resampled, y_resampled)\n",
    "#use random forest\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "evaluate_model(model, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "      <th>net.capital</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_Not-in-family</th>\n",
       "      <th>relationship_Other-relative</th>\n",
       "      <th>relationship_Own-child</th>\n",
       "      <th>relationship_Unmarried</th>\n",
       "      <th>relationship_Wife</th>\n",
       "      <th>race_Asian-Pac-Islander</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "      <th>sex_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>223881</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>149118</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>109209</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>229566</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>111963</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education.num  hours.per.week  income_>50K  net.capital  \\\n",
       "0   40  223881             15              70            1        99999   \n",
       "1   30  149118              9              40            0            0   \n",
       "2   46  109209             10              40            1            0   \n",
       "3   32  229566             11              60            1            0   \n",
       "5   63  111963             10              16            0            0   \n",
       "\n",
       "   workclass_Local-gov  workclass_Private  workclass_Self-emp-inc  \\\n",
       "0                    0                  0                       0   \n",
       "1                    0                  1                       0   \n",
       "2                    0                  1                       0   \n",
       "3                    0                  1                       0   \n",
       "5                    0                  1                       0   \n",
       "\n",
       "   workclass_Self-emp-not-inc  ...  relationship_Not-in-family  \\\n",
       "0                           1  ...                           0   \n",
       "1                           0  ...                           1   \n",
       "2                           0  ...                           0   \n",
       "3                           0  ...                           0   \n",
       "5                           0  ...                           0   \n",
       "\n",
       "   relationship_Other-relative  relationship_Own-child  \\\n",
       "0                            0                       0   \n",
       "1                            0                       0   \n",
       "2                            0                       0   \n",
       "3                            0                       0   \n",
       "5                            0                       0   \n",
       "\n",
       "   relationship_Unmarried  relationship_Wife  race_Asian-Pac-Islander  \\\n",
       "0                       0                  0                        0   \n",
       "1                       0                  0                        0   \n",
       "2                       0                  0                        0   \n",
       "3                       0                  0                        0   \n",
       "5                       0                  0                        0   \n",
       "\n",
       "   race_Black  race_Other  race_White  sex_Male  \n",
       "0           0           0           1         1  \n",
       "1           0           0           1         0  \n",
       "2           0           0           1         1  \n",
       "3           0           0           1         1  \n",
       "5           0           0           1         1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled[['fnlwgt', 'education.num','hours.per.week', 'net.capital', 'age']] = scaler.fit_transform(X_resampled[['fnlwgt', 'education.num','hours.per.week', 'net.capital', 'age']])\n",
    "X_test[['fnlwgt', 'education.num','hours.per.week', 'net.capital', 'age']] = scaler.transform(X_test[['fnlwgt', 'education.num','hours.per.week', 'net.capital', 'age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_>50K\n",
       "0    10735\n",
       "1    10735\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Siatka hiperparametrów\n",
    "param_grid = {\n",
    "    'n_estimators': [3, 5, 10, 20, 50, 100],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',  # Możesz zmienić na inne, np. 'f1', 'roc_auc', 'neg_mean_squared_error'\n",
    "    cv=5,  # Liczba podziałów walidacji krzyżowej\n",
    "    verbose=2,  # Wyświetlanie postępu\n",
    "    n_jobs=-1  # Użycie wszystkich rdzeni procesora\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END .....................max_depth=None, n_estimators=3; total time=   0.0s\n",
      "[CV] END .....................max_depth=None, n_estimators=3; total time=   0.0s\n",
      "[CV] END .....................max_depth=None, n_estimators=3; total time=   0.1s\n",
      "[CV] END .....................max_depth=None, n_estimators=3; total time=   0.0s\n",
      "[CV] END .....................max_depth=None, n_estimators=3; total time=   0.0s\n",
      "[CV] END .....................max_depth=None, n_estimators=5; total time=   0.1s\n",
      "[CV] END .....................max_depth=None, n_estimators=5; total time=   0.1s\n",
      "[CV] END .....................max_depth=None, n_estimators=5; total time=   0.1s\n",
      "[CV] END .....................max_depth=None, n_estimators=5; total time=   0.1s\n",
      "[CV] END .....................max_depth=None, n_estimators=5; total time=   0.1s\n",
      "[CV] END ....................max_depth=None, n_estimators=10; total time=   0.2s\n",
      "[CV] END ....................max_depth=None, n_estimators=10; total time=   0.2s\n",
      "[CV] END ....................max_depth=None, n_estimators=10; total time=   0.1s\n",
      "[CV] END ....................max_depth=None, n_estimators=10; total time=   0.2s\n",
      "[CV] END ....................max_depth=None, n_estimators=10; total time=   0.1s\n",
      "[CV] END ....................max_depth=None, n_estimators=20; total time=   0.3s\n",
      "[CV] END ....................max_depth=None, n_estimators=20; total time=   0.3s\n",
      "[CV] END ........................max_depth=5, n_estimators=3; total time=   0.0s\n",
      "[CV] END ....................max_depth=None, n_estimators=20; total time=   0.3s\n",
      "[CV] END ........................max_depth=5, n_estimators=3; total time=   0.0s\n",
      "[CV] END ........................max_depth=5, n_estimators=3; total time=   0.0s\n",
      "[CV] END ........................max_depth=5, n_estimators=3; total time=   0.0s\n",
      "[CV] END ....................max_depth=None, n_estimators=20; total time=   0.3s\n",
      "[CV] END ....................max_depth=None, n_estimators=20; total time=   0.3s\n",
      "[CV] END ........................max_depth=5, n_estimators=3; total time=   0.0s\n",
      "[CV] END ........................max_depth=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END ........................max_depth=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END ........................max_depth=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END ........................max_depth=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END ........................max_depth=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END ....................max_depth=None, n_estimators=50; total time=   0.7s\n",
      "[CV] END ....................max_depth=None, n_estimators=50; total time=   0.7s\n",
      "[CV] END .......................max_depth=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END ....................max_depth=None, n_estimators=50; total time=   0.7s\n",
      "[CV] END .......................max_depth=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END ....................max_depth=None, n_estimators=50; total time=   0.7s\n",
      "[CV] END .......................max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...................max_depth=None, n_estimators=100; total time=   1.4s\n",
      "[CV] END ....................max_depth=None, n_estimators=50; total time=   0.8s\n",
      "[CV] END .......................max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END .......................max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...................max_depth=None, n_estimators=100; total time=   1.6s\n",
      "[CV] END .......................max_depth=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END .......................max_depth=10, n_estimators=3; total time=   0.0s\n",
      "[CV] END .......................max_depth=10, n_estimators=3; total time=   0.0s\n",
      "[CV] END .......................max_depth=10, n_estimators=3; total time=   0.0s\n",
      "[CV] END .......................max_depth=10, n_estimators=3; total time=   0.0s\n",
      "[CV] END .......................max_depth=10, n_estimators=3; total time=   0.0s\n",
      "[CV] END .......................max_depth=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END .......................max_depth=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END .......................max_depth=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END .......................max_depth=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END ......................max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END .......................max_depth=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END ......................max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ......................max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ......................max_depth=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END ...................max_depth=None, n_estimators=100; total time=   1.5s\n",
      "[CV] END ......................max_depth=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END ......................max_depth=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END ......................max_depth=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END ......................max_depth=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END ......................max_depth=10, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ......................max_depth=10, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ......................max_depth=10, n_estimators=20; total time=   0.2s\n",
      "[CV] END ...................max_depth=None, n_estimators=100; total time=   1.5s\n",
      "[CV] END .......................max_depth=20, n_estimators=3; total time=   0.0s\n",
      "[CV] END ......................max_depth=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END .......................max_depth=20, n_estimators=3; total time=   0.1s\n",
      "[CV] END .......................max_depth=20, n_estimators=3; total time=   0.1s\n",
      "[CV] END .......................max_depth=20, n_estimators=3; total time=   0.0s\n",
      "[CV] END .......................max_depth=20, n_estimators=3; total time=   0.0s\n",
      "[CV] END ......................max_depth=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END ......................max_depth=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END .......................max_depth=20, n_estimators=5; total time=   0.1s\n",
      "[CV] END .......................max_depth=20, n_estimators=5; total time=   0.1s\n",
      "[CV] END ...................max_depth=None, n_estimators=100; total time=   1.6s\n",
      "[CV] END .......................max_depth=20, n_estimators=5; total time=   0.1s\n",
      "[CV] END .......................max_depth=20, n_estimators=5; total time=   0.1s\n",
      "[CV] END ......................max_depth=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END .......................max_depth=20, n_estimators=5; total time=   0.1s\n",
      "[CV] END ......................max_depth=20, n_estimators=10; total time=   0.2s\n",
      "[CV] END ......................max_depth=20, n_estimators=10; total time=   0.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END ......................max_depth=20, n_estimators=10; total time=   0.2s\n",
      "[CV] END ......................max_depth=20, n_estimators=10; total time=   0.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......................max_depth=20, n_estimators=10; total time=   0.1s\n",
      "[CV] END ......................max_depth=20, n_estimators=20; total time=   0.3s\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......................max_depth=20, n_estimators=20; total time=   0.3s\n",
      "[CV] END ......................max_depth=20, n_estimators=20; total time=   0.3s\n",
      "[CV] END ......................max_depth=20, n_estimators=20; total time=   0.3s\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......................max_depth=20, n_estimators=20; total time=   0.3s\n",
      "[CV] END .......................max_depth=30, n_estimators=3; total time=   0.1s\n",
      "[CV] END ......................max_depth=20, n_estimators=50; total time=   0.7s\n",
      "[CV] END .......................max_depth=30, n_estimators=3; total time=   0.1s\n",
      "[CV] END ......................max_depth=20, n_estimators=50; total time=   0.7s\n",
      "[CV] END .......................max_depth=30, n_estimators=3; total time=   0.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END .......................max_depth=30, n_estimators=3; total time=   0.0s\n",
      "[CV] END .......................max_depth=30, n_estimators=3; total time=   0.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END ......................max_depth=20, n_estimators=50; total time=   0.7s\n",
      "[CV] END .......................max_depth=30, n_estimators=5; total time=   0.1s\n",
      "[CV] END .......................max_depth=30, n_estimators=5; total time=   0.1s\n",
      "[CV] END .......................max_depth=30, n_estimators=5; total time=   0.1s\n",
      "[CV] END .......................max_depth=30, n_estimators=5; total time=   0.1s\n",
      "[CV] END .......................max_depth=30, n_estimators=5; total time=   0.1s\n",
      "[CV] END ......................max_depth=30, n_estimators=10; total time=   0.1s\n",
      "[CV] END ......................max_depth=20, n_estimators=50; total time=   0.6s\n",
      "[CV] END ......................max_depth=30, n_estimators=10; total time=   0.2s\n",
      "[CV] END ......................max_depth=20, n_estimators=50; total time=   0.7s\n",
      "[CV] END ......................max_depth=30, n_estimators=10; total time=   0.2s\n",
      "[CV] END ......................max_depth=30, n_estimators=10; total time=   0.2s\n",
      "[CV] END ......................max_depth=30, n_estimators=10; total time=   0.2s\n",
      "[CV] END ......................max_depth=30, n_estimators=20; total time=   0.3s\n",
      "[CV] END ......................max_depth=30, n_estimators=20; total time=   0.3s\n",
      "[CV] END .....................max_depth=20, n_estimators=100; total time=   1.4s\n",
      "[CV] END ......................max_depth=30, n_estimators=20; total time=   0.3s\n",
      "[CV] END .....................max_depth=20, n_estimators=100; total time=   1.3s\n",
      "[CV] END ......................max_depth=30, n_estimators=20; total time=   0.4s\n",
      "[CV] END ......................max_depth=30, n_estimators=20; total time=   0.3s\n",
      "[CV] END .....................max_depth=20, n_estimators=100; total time=   1.3s\n",
      "[CV] END ......................max_depth=30, n_estimators=50; total time=   0.8s\n",
      "[CV] END ......................max_depth=30, n_estimators=50; total time=   0.8s\n",
      "[CV] END ......................max_depth=30, n_estimators=50; total time=   0.8s\n",
      "[CV] END ......................max_depth=30, n_estimators=50; total time=   0.8s\n",
      "[CV] END ......................max_depth=30, n_estimators=50; total time=   0.8s\n",
      "[CV] END .....................max_depth=20, n_estimators=100; total time=   1.4s\n",
      "[CV] END .....................max_depth=20, n_estimators=100; total time=   1.4s\n",
      "[CV] END .....................max_depth=30, n_estimators=100; total time=   1.4s\n",
      "[CV] END .....................max_depth=30, n_estimators=100; total time=   1.5s\n",
      "[CV] END .....................max_depth=30, n_estimators=100; total time=   1.4s\n",
      "[CV] END .....................max_depth=30, n_estimators=100; total time=   1.3s\n",
      "[CV] END .....................max_depth=30, n_estimators=100; total time=   1.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5, 10, 20, 30],\n",
       "                         &#x27;n_estimators&#x27;: [3, 5, 10, 20, 50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5, 10, 20, 30],\n",
       "                         &#x27;n_estimators&#x27;: [3, 5, 10, 20, 50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 5, 10, 20, 30],\n",
       "                         'n_estimators': [3, 5, 10, 20, 50, 100]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry: {'max_depth': 30, 'n_estimators': 100}\n",
      "Najlepszy wynik: 0.8740102468560783\n"
     ]
    }
   ],
   "source": [
    "print(\"Najlepsze parametry:\", grid_search.best_params_)\n",
    "print(\"Najlepszy wynik:\", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność na zbiorze testowym: 0.8456443484521239\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Dokładność na zbiorze testowym:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TransformerMixin.fit_transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[1;32m      3\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 4\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform()\n\u001b[1;32m      7\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m      8\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(), param_grid, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: TransformerMixin.fit_transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'poly', 'rbf'], 'degree': [2, 3, 4, 5], 'gamma': ['scale', 'auto']}\n",
    "grid_svc = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, n_jobs=-1)\n",
    "grid_svc.fit(X_resampled, y_resampled)\n",
    "grid_svc.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_svc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate_model(grid_svc\u001b[38;5;241m.\u001b[39mbest_estimator_, X_resampled, y_resampled, X_test, y_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_svc' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(grid_svc.best_estimator_, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-01 16:55:09,458] A new study created in memory with name: no-name-77e2a527-72b0-4c34-bf89-3f95af75f434\n",
      "/var/folders/hh/pvrf3bcn1_19pfvwcv0z6n_m0000gn/T/ipykernel_66983/631451903.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-10, 1e10)\n",
      "[W 2025-01-01 17:11:31,562] Trial 0 failed with parameters: {'C': 11648696.282830592, 'kernel': 'linear', 'degree': 5, 'gamma': 'auto'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/hh/pvrf3bcn1_19pfvwcv0z6n_m0000gn/T/ipykernel_66983/631451903.py\", line 11, in objective\n",
      "    score = cross_val_score(model, X_train_scaled, y_train, n_jobs=-1, cv=5).mean()\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 719, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 430, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-01 17:11:31,566] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[44], line 16\u001b[0m\n",
      "\u001b[1;32m     14\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# optimize the objective function\u001b[39;00m\n",
      "\u001b[0;32m---> 16\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# get best params\u001b[39;00m\n",
      "\u001b[1;32m     18\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n",
      "\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n",
      "\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n",
      "\u001b[1;32m    385\u001b[0m \n",
      "\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n",
      "\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 475\u001b[0m     _optimize(\n",
      "\u001b[1;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n",
      "\u001b[1;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n",
      "\u001b[1;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n",
      "\u001b[1;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n",
      "\u001b[1;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n",
      "\u001b[1;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n",
      "\u001b[1;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n",
      "\u001b[1;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n",
      "\u001b[1;32m    485\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;32m---> 63\u001b[0m         _optimize_sequential(\n",
      "\u001b[1;32m     64\u001b[0m             study,\n",
      "\u001b[1;32m     65\u001b[0m             func,\n",
      "\u001b[1;32m     66\u001b[0m             n_trials,\n",
      "\u001b[1;32m     67\u001b[0m             timeout,\n",
      "\u001b[1;32m     68\u001b[0m             catch,\n",
      "\u001b[1;32m     69\u001b[0m             callbacks,\n",
      "\u001b[1;32m     70\u001b[0m             gc_after_trial,\n",
      "\u001b[1;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[1;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[1;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n",
      "\u001b[1;32m     74\u001b[0m         )\n",
      "\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n",
      "\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n",
      "\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n",
      "\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n",
      "\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n",
      "\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n",
      "\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n",
      "\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n",
      "\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n",
      "\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n",
      "\u001b[1;32m    247\u001b[0m ):\n",
      "\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n",
      "\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n",
      "\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n",
      "\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n",
      "\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n",
      "\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "\n",
      "Cell \u001b[0;32mIn[44], line 11\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n",
      "\u001b[1;32m      9\u001b[0m gamma \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m SVC(C\u001b[38;5;241m=\u001b[39mC, kernel\u001b[38;5;241m=\u001b[39mkernel, degree\u001b[38;5;241m=\u001b[39mdegree, gamma\u001b[38;5;241m=\u001b[39mgamma)\n",
      "\u001b[0;32m---> 11\u001b[0m score \u001b[38;5;241m=\u001b[39m cross_val_score(model, X_train_scaled, y_train, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[1;32m    211\u001b[0m         )\n",
      "\u001b[1;32m    212\u001b[0m     ):\n",
      "\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n",
      "\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n",
      "\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n",
      "\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n",
      "\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n",
      "\u001b[1;32m    223\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n",
      "\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n",
      "\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n",
      "\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n",
      "\u001b[1;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n",
      "\u001b[1;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n",
      "\u001b[1;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n",
      "\u001b[1;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n",
      "\u001b[1;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n",
      "\u001b[1;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n",
      "\u001b[1;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n",
      "\u001b[1;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n",
      "\u001b[1;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n",
      "\u001b[1;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n",
      "\u001b[1;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n",
      "\u001b[1;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n",
      "\u001b[1;32m    732\u001b[0m )\n",
      "\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[1;32m    211\u001b[0m         )\n",
      "\u001b[1;32m    212\u001b[0m     ):\n",
      "\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n",
      "\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n",
      "\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n",
      "\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n",
      "\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n",
      "\u001b[1;32m    223\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n",
      "\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n",
      "\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n",
      "\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n",
      "\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n",
      "\u001b[1;32m    431\u001b[0m     delayed(_fit_and_score)(\n",
      "\u001b[1;32m    432\u001b[0m         clone(estimator),\n",
      "\u001b[1;32m    433\u001b[0m         X,\n",
      "\u001b[1;32m    434\u001b[0m         y,\n",
      "\u001b[1;32m    435\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n",
      "\u001b[1;32m    436\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n",
      "\u001b[1;32m    437\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n",
      "\u001b[1;32m    438\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n",
      "\u001b[1;32m    439\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[1;32m    440\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n",
      "\u001b[1;32m    441\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n",
      "\u001b[1;32m    442\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n",
      "\u001b[1;32m    443\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[1;32m    444\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n",
      "\u001b[1;32m    445\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n",
      "\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n",
      "\u001b[1;32m    448\u001b[0m )\n",
      "\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n",
      "\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n",
      "\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n",
      "\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n",
      "\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n",
      "\u001b[1;32m     66\u001b[0m )\n",
      "\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n",
      "\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n",
      "\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n",
      "\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n",
      "\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n",
      "\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n",
      "\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n",
      "\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n",
      "\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n",
      "\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n",
      "\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n",
      "\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n",
      "\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n",
      "\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n",
      "\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n",
      "\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n",
      "\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n",
      "\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n",
      "\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n",
      "\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #find best params using optuna\n",
    "# import optuna\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# # find best params for svc model using optuna\n",
    "# def objective(trial):\n",
    "#     C = trial.suggest_loguniform('C', 1e-10, 1e10)\n",
    "#     kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n",
    "#     degree = trial.suggest_int('degree', 2, 5)\n",
    "#     gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "#     model = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma)\n",
    "#     score = cross_val_score(model, X_train_scaled, y_train, n_jobs=-1, cv=5).mean()\n",
    "#     return score\n",
    "# # create study object\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# # optimize the objective function\n",
    "# study.optimize(objective, n_trials=100)\n",
    "# # get best params\n",
    "# best_params = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN i KKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.3s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.3s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.5s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.3s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.3s\n",
      "[CV] END ...metric=euclidean, n_neighbors=9, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=9, weights=uniform; total time=   0.3s\n",
      "[CV] END ...metric=euclidean, n_neighbors=9, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=9, weights=distance; total time=   0.3s\n",
      "[CV] END ...metric=euclidean, n_neighbors=9, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=euclidean, n_neighbors=9, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=9, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=9, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=9, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=9, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=13, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=13, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=13, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=13, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=euclidean, n_neighbors=13, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=13, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=euclidean, n_neighbors=13, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=euclidean, n_neighbors=13, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=euclidean, n_neighbors=13, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=euclidean, n_neighbors=13, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=15, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=15, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=15, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=euclidean, n_neighbors=15, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=euclidean, n_neighbors=15, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=15, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=euclidean, n_neighbors=15, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=euclidean, n_neighbors=15, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=euclidean, n_neighbors=15, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=euclidean, n_neighbors=15, weights=distance; total time=   0.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   1.2s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   1.2s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   1.2s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   1.2s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   1.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   1.2s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   1.2s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   1.4s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   1.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   1.2s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   1.2s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   1.2s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   1.2s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   1.2s\n",
      "[CV] END ...metric=manhattan, n_neighbors=9, weights=uniform; total time=   1.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   1.5s\n",
      "[CV] END ...metric=manhattan, n_neighbors=9, weights=uniform; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=9, weights=uniform; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=9, weights=distance; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=9, weights=uniform; total time=   1.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=9, weights=uniform; total time=   1.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=9, weights=distance; total time=   1.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=9, weights=distance; total time=   1.1s\n",
      "[CV] END ..metric=manhattan, n_neighbors=9, weights=distance; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=9, weights=distance; total time=   1.2s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   1.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   1.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   1.2s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   1.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   1.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   1.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   1.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=13, weights=uniform; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=13, weights=uniform; total time=   1.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=13, weights=uniform; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=13, weights=uniform; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=13, weights=uniform; total time=   1.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=13, weights=distance; total time=   1.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=13, weights=distance; total time=   1.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=13, weights=distance; total time=   1.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=13, weights=distance; total time=   1.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=13, weights=distance; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=15, weights=uniform; total time=   1.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=15, weights=uniform; total time=   1.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=15, weights=uniform; total time=   1.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=15, weights=uniform; total time=   1.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=15, weights=distance; total time=   1.2s\n",
      "[CV] END ..metric=manhattan, n_neighbors=15, weights=uniform; total time=   1.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=15, weights=distance; total time=   1.2s\n",
      "[CV] END .metric=manhattan, n_neighbors=15, weights=distance; total time=   1.2s\n",
      "[CV] END .metric=manhattan, n_neighbors=15, weights=distance; total time=   1.1s\n",
      "[CV] END .metric=manhattan, n_neighbors=15, weights=distance; total time=   1.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'distance'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid search for knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}\n",
    "grid_kknn = GridSearchCV(KNeighborsClassifier(), param_grid, refit=True, verbose=2, n_jobs=-1)\n",
    "grid_kknn.fit(X_resampled, y_resampled)\n",
    "grid_kknn.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metryki dla danych treningowych:\n",
      "Accuracy: 1.0000\n",
      "AUC: 1.0000\n",
      "F1: 1.0000\n",
      "\n",
      "Classification Report dla danych treningowych:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10735\n",
      "           1       1.00      1.00      1.00     10735\n",
      "\n",
      "    accuracy                           1.00     21470\n",
      "   macro avg       1.00      1.00      1.00     21470\n",
      "weighted avg       1.00      1.00      1.00     21470\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metryki dla danych testowych:\n",
      "Accuracy: 0.8132\n",
      "AUC: 0.7829\n",
      "F1: 0.6570\n",
      "\n",
      "Classification Report dla danych testowych:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87      5227\n",
      "           1       0.60      0.72      0.66      1718\n",
      "\n",
      "    accuracy                           0.81      6945\n",
      "   macro avg       0.75      0.78      0.76      6945\n",
      "weighted avg       0.83      0.81      0.82      6945\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluate model kkn with best params\n",
    "evaluate_model(grid_kknn.best_estimator_, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   2.9s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   2.9s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   2.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   2.9s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.8s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.01, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   2.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   2.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=0.1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   1.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   2.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   3.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   2.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   2.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   7.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   7.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   7.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   7.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   7.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.2s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.5s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.4s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.8s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.7s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   4.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=1, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.9s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.4s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   3.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.6s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   3.1s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.2s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.7s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   3.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   3.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.4s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.8s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.9s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.3s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=10, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.6s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   2.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   2.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.9s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   2.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   2.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.6s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.6s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   3.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   3.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   4.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.2s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.5s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.4s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   5.3s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=True, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.0001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   2.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=100, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.5s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   1.8s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.001; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.5s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.8s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   3.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.8s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.0001; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l1, solver=saga, tol=0.0001; total time=   3.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=200, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=liblinear, tol=0.0001; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=liblinear, tol=0.0001; total time=   0.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.01; total time=   0.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   0.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.3s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   4.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.0001; total time=   0.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.001; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.5s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.01; total time=   0.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.8s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=lbfgs, tol=0.001; total time=   1.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=elasticnet, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.1s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=liblinear, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   1.2s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=saga, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   4.9s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=lbfgs, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.0001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.001; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=none, solver=newton-cg, tol=0.01; total time=   0.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   2.0s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   2.5s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   1.6s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.01; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.001; total time=   0.7s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=newton-cg, tol=0.0001; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l2, solver=saga, tol=0.0001; total time=   1.4s\n",
      "[CV] END C=100, fit_intercept=False, max_iter=500, penalty=l1, solver=saga, tol=0.0001; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "4500 fits failed out of a total of 7200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1182, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "908 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "234 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "258 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.80704411 0.80271147 0.79441886 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 200,\n",
       " 'penalty': 'l1',\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search for Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definicja siatki parametrów\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularyzacja (hiperparametr C)\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],  # Typ regularyzacji\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg'],  # Algorytm optymalizacji\n",
    "    'max_iter': [100, 200, 500],  # Maksymalna liczba iteracji\n",
    "    'fit_intercept': [True, False],  # Czy dopasować wyraz wolny (intercept)\n",
    "    'tol': [1e-4, 1e-3, 1e-2],  # Tolerancja zbieżności\n",
    "}\n",
    "\n",
    "# Tworzenie obiektu GridSearchCV\n",
    "grid_lr = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=param_grid,\n",
    "    refit=True,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_resampled, y_resampled)\n",
    "grid_lr.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 200,\n",
       " 'penalty': 'l1',\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metryki dla danych treningowych:\n",
      "Accuracy: 0.8155\n",
      "AUC: 0.8155\n",
      "F1: 0.8199\n",
      "\n",
      "Classification Report dla danych treningowych:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81     10733\n",
      "           1       0.80      0.84      0.82     10733\n",
      "\n",
      "    accuracy                           0.82     21466\n",
      "   macro avg       0.82      0.82      0.82     21466\n",
      "weighted avg       0.82      0.82      0.82     21466\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metryki dla danych testowych:\n",
      "Accuracy: 0.8066\n",
      "AUC: 0.8192\n",
      "F1: 0.6835\n",
      "\n",
      "Classification Report dla danych testowych:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86      5227\n",
      "           1       0.57      0.84      0.68      1718\n",
      "\n",
      "    accuracy                           0.81      6945\n",
      "   macro avg       0.76      0.82      0.77      6945\n",
      "weighted avg       0.85      0.81      0.82      6945\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(grid_lr.best_estimator_, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
